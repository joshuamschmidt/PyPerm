#!/usr/bin/env python
import argparse
import os
from pathlib import Path
import sys
import textwrap
from set_perm import set_perm as sp
import pandas as pd
import numpy as np

'''required and optional argument parser'''

parser = argparse.ArgumentParser(prog='set_perm',
                        formatter_class=argparse.RawDescriptionHelpFormatter,
                        description=textwrap.dedent('''\
                        Simple Gene Set enrichment test
                        --------------------------------------------
                        Generates a gene set enrichment test report file
                        for each input file/background sets.
                        
                        NOTES:
                        Number of background files must much number of candidate files.
                        Candidate SNP/Fatures must be a subset of background files.

                        !!!!!Python needs to be >=3.9!!!!!!
                        '''),
                        add_help=False,
                        epilog="Questions, bugs etc?\njoshmschmidt1@gmail.com\ngithub.com/joshuamschmidt")
parser._action_groups.pop()
required = parser.add_argument_group('required arguments')
optional = parser.add_argument_group('optional arguments')

# Add back help 
optional.add_argument(
    '-h',
    '--help',
    action='help',
    default=argparse.SUPPRESS,
    help='show this help message and exit'
)
required.add_argument('--candidates', type=str, dest='c_files', nargs='+', default=[],
                    help='one or more candidate snp/feature files. Must be passed as a comma sep name,file tuple')

required.add_argument('--background', type=str, dest='b_files', nargs='+', default=[],
                    help='one or more background snp/feature files. Must be passed as a comma sep name,file tuple')

required.add_argument('--feature_def', type=str, dest='feature_def',
                    help='file that defines features e.g. genes: chr start stop name')

required.add_argument('--function_def', type=str, dest='function_def',
                    help='file that defines function sets')

optional.add_argument('--min_set_size', dest='min_set_size', type=int,
                       help='set minium number of genes required in feature set. Default: 10')
parser.set_defaults(min_set_size=10)

optional.add_argument('--n_perms', dest='n_perms', type=int,
                       help='Number of random permuations for p-value estimation. Default: 10,000')
parser.set_defaults(n_perms=10000)

optional.add_argument('--prefix', dest='user_prefix', type=str,
                       help='Prefix identifyer for output file(s). Default: ""')
parser.set_defaults(user_prefix="")

optional.add_argument('--joint', dest='joint', type=str, nargs='+', default= [],
                       help='a list of samples to be analysed jointly, e.g. a,b or a,b,c'. )

optional.add_argument('--gene_def', dest='gene_def', type=int, default= 0,
                       help='an int to specifiy if feature defs are changed in bp. Currently modfies both start and end coordinates. Default=0')

optional.add_argument('--threads', type=int, dest='threads',
                       help='multithreaded mode with int threads')


#  sorted(annotations.annotation_table[annotations.annotation_table['Idx'].isin(test_obj.candidate_array[0])]['Annotation'].values)
# sys.modules.pop('set_perm') 
#  input_list=[('central', 'data/central-0.000192-candidate.snps.bed.gz', 'data/pbsnj-bg.snps.bed.gz'), ('eastern', 'data/eastern-0.000228-candidate.snps.bed.gz', 'data/pbsnj-bg.snps.bed.gz'), ('internal', 'data/ancestral-0.005-candidate.snps.bed.gz', 'data/ancestral-bg.bed.gz')] 
def input_arg_checker(cand_tuple_list, back_tuple_list):
    if(len(cand_tuple_list) != len(back_tuple_list)):
        raise ValueError('candidate and background lists must be the same length! Aborting!')
    try:
        cand_dict=dict(cand_tuple_list)
    except:
        print("List of candidate files is not list of tuples")
    try:
        bg_dict=dict(back_tuple_list)
    except:
        print("List of background files is not list of tuples")
    if(cand_dict.keys() != bg_dict.keys()):
        raise ValueError('candidate and background lists do not have the same set of sample names! Aborting!')
    try:
        combined_list=[(k, cand_dict[k], bg_dict[k]) for k in sorted(cand_dict)]
    except:
        print("error in merging candidate and background file lists!")
    return combined_list

def main():
    args = parser.parse_args()
    annotations = sp.AnnotationSet(annotation_file=args.feature_def, range_modification=args.gene_def)
    # annotations = sp.AnnotationSet(annotation_file='data/genes.txt', range_modification=2000)   
    # function_sets = sp.FunctionSets(function_set_file='data/kegg.txt', min_set_size=10, annotation_obj=annotations) 
    function_sets = sp.FunctionSets(function_set_file=args.function_def, min_set_size=args.min_set_size, annotation_obj=annotations)
    function_name =  Path(args.function_def).stem
    # check that cand and back files are correctly named.....
    try:
       input_list=input_arg_checker(args.c_files, args.b_files)
    except:
        print("error in either candidate or background files")

    # begin
    single_cand_objs = [None] * len(input_list)
    single_test_objs = [None] * len(input_list)
    single_perm_objs = [None] * len(input_list)
    single_names = [None] * len(input_list)
    single_results = [None] * len(input_list)
    single_per_set = [None] * len(input_list)

    n_perms=arg.n_perms
    threads=arg_threads
    for j, i_group in enumerate(input_list):
        name, cands, bg = i_group
        single_names[j] = name
        cand_variants = sp.Variants(variant_file=cands)
        cand_variants.annotate_variants(annotation_obj=annotations)
        single_cand_objs[j]=cand_variants
        bg_variants =  sp.Variants(variant_file=bg)
        bg_variants.annotate_variants(annotation_obj=annotations)
        test_obj = sp.TestObject(cand_variants, bg_variants, function_sets, annotations, n_cores = threads)
        single_test_objs[j] = test_obj
        perm_obj = sp.Permutation(test_obj, n_perms, threads)
        single_perm_objs[j] = perm_obj
        per_set = sp.SetPerPerm(perm_obj, function_sets, test_obj, threads)
        single_per_set[j] = per_set
        results = sp.make_results_table(test_obj, function_sets, per_set, annotations)
        single_results[j] = results
        
    joint_list=args.joint
    # joint_list=[ ("central", "eastern"), ("central","internal"), ("eastern","internal"), ("central","eastern","internal")  ]
    if(len(joint_list)>0):
        joint_test_results = [None] * len(joint_list)
        joint_test_names = [None] * len(joint_list)
        for k, join_group in enumerate(joint_list):
            # k=0
            # join_group=joint_list[k]
            n_joins = len(join_group)
            idxs=[single_names.index(group) for group in join_group]
            joint_test_obj = sp.TestObject.add_objects(*[single_test_objs[i] for i in idxs])
            joint_per_set = sp.SetPerPerm.join_objects(*[single_per_set[i] for i in idxs])
            joint_results = sp.make_results_table(joint_obj, function_sets, joint_per_set, annotations)
            joint_test_results[k] = joint_results
            joint_test_names[k] = "_".join(join_group)
    # time to write results out
    user_prefix=args.user_prefix
    for i, result_df in enumerate(single_results):
        sp.results_writer(result_df, single_names[i], function_name, user_prefix)
    if(len(joint_list)>0):
        for i, result_df in enumerate(joint_test_results):
            sp.results_writer(result_df, joint_test_names[i], function_name, user_prefix)

if __name__ == '__main__':
    main()
